{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330206b1",
   "metadata": {
    "id": "330206b1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import os\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a3746",
   "metadata": {
    "id": "206a3746"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\kvsre\\Downloadsspam_sms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8fae43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5c8fae43",
    "outputId": "c44a819f-bbc0-4691-e26d-e33c30c5026e"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383627f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "383627f3",
    "outputId": "2fb55130-602c-48dc-f461-759245426b46"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb95055",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cb95055",
    "outputId": "e8790708-deb0-42ce-9c03-94fc4c5b8c53"
   },
   "outputs": [],
   "source": [
    "#Check the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a0d2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "017a0d2f",
    "outputId": "6e7dbf54-17c5-492e-927b-92a91b70464d"
   },
   "outputs": [],
   "source": [
    "#Check the missing values in the data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97916cb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "97916cb4",
    "outputId": "659a265f-8213-4c56-9952-89d420f7a6bc"
   },
   "outputs": [],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463510ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "463510ee",
    "outputId": "62e77531-7608-4010-cc90-64727c5f0521"
   },
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "df = data.groupby('label').size().reset_index(name='counts')\n",
    "n = df['label'].unique().__len__()+1\n",
    "all_colors = list(plt.cm.colors.cnames.keys())\n",
    "random.seed(2000)\n",
    "c = random.choices(all_colors, k=n)\n",
    "\n",
    "# Plot Bars\n",
    "plt.figure(figsize=(6,6), dpi= 80)\n",
    "plt.bar(df['label'], df['counts'], color=c, width=.5)\n",
    "for i, val in enumerate(df['counts'].values):\n",
    "    plt.text(i, val, float(val), horizontalalignment='center', verticalalignment='bottom', fontdict={'fontweight':500, 'size':12})\n",
    "\n",
    "# Decoration\n",
    "plt.gca().set_xticklabels(df['label'],rotation=60,horizontalalignment='right')\n",
    "plt.ylim(0, 4500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1f1bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "b0d1f1bd",
    "outputId": "994f9748-f1fc-4c56-ccbe-483fa6ddb779"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = data[data['label']== 'ham']\n",
    "df_minority = data[data['label']== 'spam']\n",
    "\n",
    "# Downsample majority class and upsample the minority class\n",
    "df_minority_upsampled = resample(df_minority, replace=True,n_samples=4000,random_state=123)\n",
    "df_majority_downsampled = resample(df_majority, replace=False,n_samples=4000,random_state=123)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_upsampled = pd.concat([df_minority_upsampled, df_majority_downsampled])\n",
    "\n",
    "# Display new class counts\n",
    "df_upsampled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb27a8",
   "metadata": {
    "id": "0bcb27a8"
   },
   "outputs": [],
   "source": [
    "# shuffle the DataFrame rows\n",
    "data= df_upsampled.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6200837",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "c6200837",
    "outputId": "a8c00951-152b-40c1-9252-f57cd4e025af"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Prepare Data\n",
    "df = data.groupby('label').size().reset_index(name='counts')\n",
    "n = df['label'].unique().__len__()+1\n",
    "all_colors = list(plt.cm.colors.cnames.keys())\n",
    "random.seed(2000)\n",
    "c = random.choices(all_colors, k=n)\n",
    "\n",
    "# Plot Bars\n",
    "plt.figure(figsize=(6,6), dpi= 80)\n",
    "plt.bar(df['label'], df['counts'], color=c, width=.5)\n",
    "for i, val in enumerate(df['counts'].values):\n",
    "    plt.text(i, val, float(val), horizontalalignment='center', verticalalignment='bottom', fontdict={'fontweight':500, 'size':12})\n",
    "\n",
    "# Decoration\n",
    "plt.gca().set_xticklabels(df['label'], rotation=60, horizontalalignment= 'right')\n",
    "\n",
    "plt.ylim(0, 4500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5736aba",
   "metadata": {
    "id": "a5736aba"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7407a7",
   "metadata": {
    "id": "cc7407a7"
   },
   "outputs": [],
   "source": [
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2118fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "0d2118fb",
    "outputId": "213de734-64e3-43c1-bf56-874da390a36d"
   },
   "outputs": [],
   "source": [
    "data['text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81fffb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c81fffb",
    "outputId": "1c3d56dd-d37c-4a89-eb82-283286505646"
   },
   "outputs": [],
   "source": [
    "print(\"printing some random reviews\")\n",
    "print(9, data['text'].values[9])\n",
    "print(34, data['text'].values[34])\n",
    "print(147, data['text'].values[147])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a3b69d",
   "metadata": {
    "id": "b9a3b69d"
   },
   "outputs": [],
   "source": [
    "# Combining all the above stundents\n",
    "from tqdm import tqdm\n",
    "def preprocess_text(text_data):\n",
    "    preprocessed_text = []\n",
    "    # tqdm is for printing the status bar\n",
    "    for sentance in tqdm(text_data):\n",
    "        sent = decontracted(sentance)\n",
    "        sent = sent.replace('\\\\r', ' ')\n",
    "        sent = sent.replace('\\\\n', ' ')\n",
    "        sent = sent.replace('\\\\\"', ' ')\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "        # https://gist.github.com/sebleier/554280\n",
    "        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
    "        preprocessed_text.append(sent.lower().strip())\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c71e08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5c71e08",
    "outputId": "9236eb32-9153-4b33-f3d0-e1c2187a088f"
   },
   "outputs": [],
   "source": [
    "preprocessed_text = preprocess_text(data['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2df8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bde2df8b",
    "outputId": "d7e2c9b5-2173-47b1-d974-0fcbc6629ada"
   },
   "outputs": [],
   "source": [
    "print(\"printing some random reviews\")\n",
    "print(9, preprocessed_text[9])\n",
    "print(34, preprocessed_text[34])\n",
    "print(147, preprocessed_text[147])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af0a4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "b0af0a4d",
    "outputId": "9a864c8a-a6c8-413f-d623-06c660b18b95"
   },
   "outputs": [],
   "source": [
    "data[\"label\"] = [1 if i == \"spam\" else 0 for i in data[\"label\"]]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a474e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b83a474e",
    "outputId": "63b14125-6090-4725-b077-857590514c3f"
   },
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c372f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "68c372f0",
    "outputId": "283d2ca8-95b0-40e3-f42b-00fb474d70dc"
   },
   "outputs": [],
   "source": [
    "#spam word cloud\n",
    "import matplotlib.pyplot as plt\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "wc=WordCloud(max_words=2000,width=1600,height=800).generate(' '.join(data[data.label==1].text))\n",
    "plt.imshow(wc , interpolation = 'bilinear')\n",
    "plt.title(\"Spam Word Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9947893",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "e9947893",
    "outputId": "ab8497f0-163f-43c7-e0bb-e4f6d7aba14c"
   },
   "outputs": [],
   "source": [
    "#ham word cloud\n",
    "plt.figure(figsize=(10,10))\n",
    "wc=WordCloud(max_words=2000,width=1600,height=800).generate(' '.join(data[data.label==0].text))\n",
    "plt.imshow(wc , interpolation = 'bilinear')\n",
    "plt.title(\"ham Word Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283d3fc",
   "metadata": {
    "id": "4283d3fc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y=np.array(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29944649",
   "metadata": {
    "id": "29944649"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Breaking into Train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_text, y, test_size=0.3,stratify=y ,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ec948",
   "metadata": {
    "id": "8a6ec948"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae1268",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dae1268",
    "outputId": "33989836-3f64-428f-a6c9-82b07d8e2cf4"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "count_trans = count_vect.fit(X_train) # fit has to happen only on train data\n",
    "\n",
    "# Dump the file\n",
    "pickle.dump(count_trans, open(r\"C:\\Users\\HP\\Music\\SMS_SPAM\\FRONTEND\\count_vect.pkl\", \"wb\"))\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "count = pickle.load(open(r\"C:\\Users\\HP\\Music\\SMS_SPAM\\FRONTEND\\count_vect.pkl\", 'rb'))\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "X_train_count =count.transform(X_train)\n",
    "X_test_count = count.transform(X_test)\n",
    "\n",
    "#Normalize Data\n",
    "X_train_count = preprocessing.normalize(X_train_count)\n",
    "print(\"Train Data Size: \",X_train_count.shape)\n",
    "\n",
    "#Normalize Data\n",
    "X_test_count = preprocessing.normalize(X_test_count)\n",
    "print(\"Test Data Size: \",X_test_count.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf2b02",
   "metadata": {
    "id": "79cf2b02"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0u9HsKPxovnZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0u9HsKPxovnZ",
    "outputId": "b489b187-cfb4-4ffd-b445-bb51f24ae4e4"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JL_bZsfOom-1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "JL_bZsfOom-1",
    "outputId": "874add5c-b3d5-40ec-a139-6a91de4155d1"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Initialize and train CatBoost model\n",
    "catboost_model = CatBoostClassifier(iterations=500, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=0)\n",
    "catboost_model.fit(X_train_count, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "filename = r'C:\\Users\\HP\\Music\\SMS_SPAM\\FRONTEND\\catboost.pkl'\n",
    "pickle.dump(catboost_model, open(filename, 'wb'))\n",
    "\n",
    "# Predict on test and train data\n",
    "pred_test = catboost_model.predict(X_test_count)\n",
    "test_accuracy = accuracy_score(y_test, pred_test)\n",
    "pred_train = catboost_model.predict(X_train_count)\n",
    "train_accuracy = accuracy_score(y_train, pred_train)\n",
    "\n",
    "print(\"Accuracy on Test data is \" + str(test_accuracy))\n",
    "print(\"Accuracy on Train data is \" + str(train_accuracy))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# Code for drawing seaborn heatmaps\n",
    "class_names = ['HAM', 'SPAM']\n",
    "df_heatmap = pd.DataFrame(confusion_matrix(y_test, pred_test), index=class_names, columns=class_names)\n",
    "fig = plt.figure()\n",
    "heatmap = sns.heatmap(df_heatmap, annot=True, fmt=\"d\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ivnV7mENonBw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivnV7mENonBw",
    "outputId": "fff6236e-f0e0-4e05-b808-4023c029fd27"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "class_names = ['HAM','SPAM']\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pred_test, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eF1OPFbeo_0u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "eF1OPFbeo_0u",
    "outputId": "ed52cdce-ed9e-436d-cf30-b728fc82040f"
   },
   "outputs": [],
   "source": [
    "original =  [\"SPAM\" if x==1 else \"HAM\" for x in y_test[:20]]\n",
    "predicted = catboost_model.predict(X_test_count[:20])\n",
    "pred = []\n",
    "\n",
    "for i in predicted:\n",
    "  if i == 1:\n",
    "    k = \"SPAM\"\n",
    "    pred.append(k)\n",
    "  else:\n",
    "    k = \"HAM\"\n",
    "    pred.append(k)\n",
    "# Creating a data frame\n",
    "df = pd.DataFrame(list(zip(X_test[:20],original, pred,)),\n",
    "               columns =['Text','original_Classlabel', 'predicted_classlebel'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3DLwnDELo_3g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "3DLwnDELo_3g",
    "outputId": "e5b74b50-94d7-41cd-a7b7-ffa6648aa3cc"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train XGBoost model\n",
    "xgb_model = XGBClassifier(n_estimators=500, max_depth=6, learning_rate=0.1, objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train_count, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "filename = r'C:\\Users\\HP\\Music\\SMS_SPAM\\FRONTEND\\xgb.pkl'\n",
    "pickle.dump(xgb_model, open(filename, 'wb'))\n",
    "\n",
    "# Predict on test and train data\n",
    "pred_test = xgb_model.predict(X_test_count)\n",
    "test_accuracy = accuracy_score(y_test, pred_test)\n",
    "pred_train = xgb_model.predict(X_train_count)\n",
    "train_accuracy = accuracy_score(y_train, pred_train)\n",
    "\n",
    "print(\"Accuracy on Test data is \" + str(test_accuracy))\n",
    "print(\"Accuracy on Train data is \" + str(train_accuracy))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# Code for drawing seaborn heatmaps\n",
    "class_names = ['HAM', 'SPAM']\n",
    "df_heatmap = pd.DataFrame(confusion_matrix(y_test, pred_test), index=class_names, columns=class_names)\n",
    "fig = plt.figure()\n",
    "heatmap = sns.heatmap(df_heatmap, annot=True, fmt=\"d\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BKPdl3ino_6L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKPdl3ino_6L",
    "outputId": "8bb73dc9-7763-4f8e-8e56-252e4f0061d9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "class_names = ['HAM','SPAM']\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pred_test, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WIxhPhUoo_9t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "WIxhPhUoo_9t",
    "outputId": "cd792d54-f9f0-4023-aebc-49eae875762a"
   },
   "outputs": [],
   "source": [
    "original =  [\"SPAM\" if x==1 else \"HAM\" for x in y_test[:20]]\n",
    "predicted = xgb_model.predict(X_test_count[:20])\n",
    "pred = []\n",
    "\n",
    "for i in predicted:\n",
    "  if i == 1:\n",
    "    k = \"SPAM\"\n",
    "    pred.append(k)\n",
    "  else:\n",
    "    k = \"HAM\"\n",
    "    pred.append(k)\n",
    "# Creating a data frame\n",
    "df = pd.DataFrame(list(zip(X_test[:20],original, pred,)),\n",
    "               columns =['Text','original_Classlabel', 'predicted_classlebel'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N3kdmOWNonFE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "N3kdmOWNonFE",
    "outputId": "8b94b134-5a8e-4eb3-be6d-4c6813ba7392"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Initialize and train LightGBM model\n",
    "lgbm_model = LGBMClassifier(n_estimators=500, max_depth=6, learning_rate=0.1, objective='binary')\n",
    "lgbm_model.fit(X_train_count, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "filename = r'C:\\Users\\HP\\Music\\SMS_SPAM\\FRONTEND\\lgbm.pkl'\n",
    "pickle.dump(lgbm_model, open(filename, 'wb'))\n",
    "\n",
    "# Predict on test and train data\n",
    "pred_test = lgbm_model.predict(X_test_count)\n",
    "test_accuracy = accuracy_score(y_test, pred_test)\n",
    "pred_train = lgbm_model.predict(X_train_count)\n",
    "train_accuracy = accuracy_score(y_train, pred_train)\n",
    "\n",
    "print(\"Accuracy on Test data is \" + str(test_accuracy))\n",
    "print(\"Accuracy on Train data is \" + str(train_accuracy))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# Code for drawing seaborn heatmaps\n",
    "class_names = ['HAM', 'SPAM']\n",
    "df_heatmap = pd.DataFrame(confusion_matrix(y_test, pred_test), index=class_names, columns=class_names)\n",
    "fig = plt.figure()\n",
    "heatmap = sns.heatmap(df_heatmap, annot=True, fmt=\"d\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R26_9YYZp7ew",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R26_9YYZp7ew",
    "outputId": "eb745870-4fcc-4398-86fd-a1dfa00a5493"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "class_names = ['HAM','SPAM']\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pred_test, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f5018",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "id": "019f5018",
    "outputId": "d4161135-3716-459e-cbfe-c3e33ec3778a"
   },
   "outputs": [],
   "source": [
    "original =  [\"SPAM\" if x==1 else \"HAM\" for x in y_test[:20]]\n",
    "predicted = lgbm_model.predict(X_test_count[:20])\n",
    "pred = []\n",
    "\n",
    "for i in predicted:\n",
    "  if i == 1:\n",
    "    k = \"SPAM\"\n",
    "    pred.append(k)\n",
    "  else:\n",
    "    k = \"HAM\"\n",
    "    pred.append(k)\n",
    "# Creating a data frame\n",
    "df = pd.DataFrame(list(zip(X_test[:20],original, pred,)),\n",
    "               columns =['Text','original_Classlabel', 'predicted_classlebel'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc5a29e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cc5a29e",
    "outputId": "c77c7451-94d0-407f-e5aa-208eb1ab5804"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize CatBoost Model\n",
    "catboost_model = CatBoostClassifier(iterations=500, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=0)\n",
    "catboost_model.fit(X_train_count, y_train)\n",
    "\n",
    "# Initialize LightGBM Model\n",
    "lgbm_model = LGBMClassifier(n_estimators=500, max_depth=6, learning_rate=0.1, objective='binary')\n",
    "lgbm_model.fit(X_train_count, y_train)\n",
    "\n",
    "# Create a Voting Classifier (Soft Voting)\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('catboost', catboost_model),\n",
    "    ('lgbm', lgbm_model)\n",
    "], voting='soft')  # Soft Voting uses probability averaging\n",
    "\n",
    "# Train the Ensemble Model\n",
    "ensemble_model.fit(X_train_count, y_train)\n",
    "\n",
    "# Predict on Test Data\n",
    "pred_test = ensemble_model.predict(X_test_count)\n",
    "test_accuracy = accuracy_score(y_test, pred_test)\n",
    "\n",
    "# Predict on Train Data\n",
    "pred_train = ensemble_model.predict(X_train_count)\n",
    "train_accuracy = accuracy_score(y_train, pred_train)\n",
    "\n",
    "print(\"Ensemble Model Accuracy on Test data: \", test_accuracy)\n",
    "print(\"Ensemble Model Accuracy on Train data: \", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8gDg-itE2Npb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8gDg-itE2Npb",
    "outputId": "94b29427-4baa-4b69-da79-731dc8762e12"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Initialize Models\n",
    "catboost_model = CatBoostClassifier(iterations=500, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=0)\n",
    "xgb_model = XGBClassifier(n_estimators=500, max_depth=6, learning_rate=0.1, objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Train Models\n",
    "catboost_model.fit(X_train_count, y_train)\n",
    "xgb_model.fit(X_train_count, y_train)\n",
    "\n",
    "# Voting Classifier (Soft Voting)\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('catboost', catboost_model),\n",
    "    ('lgbm', lgbm_model)\n",
    "], voting='soft', weights=[2, 1])\n",
    "\n",
    "ensemble_model.fit(X_train_count, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "filename = r'C:\\Users\\HP\\Music\\SMS_SPAM\\FRONTEND\\ensemble.pkl'\n",
    "pickle.dump(ensemble_model, open(filename, 'wb'))\n",
    "\n",
    "# Predict on test and train data\n",
    "pred_test = ensemble_model.predict(X_test_count)\n",
    "test_accuracy = accuracy_score(y_test, pred_test)\n",
    "pred_train = ensemble_model.predict(X_train_count)\n",
    "train_accuracy = accuracy_score(y_train, pred_train)\n",
    "\n",
    "print(\"Accuracy on ensemble_model Test data is \" + str(test_accuracy))\n",
    "print(\"Accuracy on ensemble_model Train data is \" + str(train_accuracy))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# Code for drawing seaborn heatmaps\n",
    "class_names = ['HAM', 'SPAM']\n",
    "df_heatmap = pd.DataFrame(confusion_matrix(y_test, pred_test), index=class_names, columns=class_names)\n",
    "fig = plt.figure()\n",
    "heatmap = sns.heatmap(df_heatmap, annot=True, fmt=\"d\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gj_IORYF481o",
   "metadata": {
    "id": "Gj_IORYF481o"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "class_names = ['HAM','SPAM']\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pred_test, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3977b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original =  [\"SPAM\" if x==1 else \"HAM\" for x in y_test[:20]]\n",
    "predicted = ensemble_model.predict(X_test_count[:20])\n",
    "pred = []\n",
    "\n",
    "for i in predicted:\n",
    "  if i == 1:\n",
    "    k = \"SPAM\"\n",
    "    pred.append(k)\n",
    "  else:\n",
    "    k = \"HAM\"\n",
    "    pred.append(k)\n",
    "# Creating a data frame\n",
    "df = pd.DataFrame(list(zip(X_test[:20],original, pred,)),\n",
    "               columns =['Text','original_Classlabel', 'predicted_classlebel'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ae68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_count = vectorizer.fit_transform(X_train)  # X_train should be your training text data\n",
    "X_test_count = vectorizer.transform(X_test)        # X_test for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abcc339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSpam(input_text): \n",
    "    # Display input\n",
    "    print('Input:', input_text)\n",
    "\n",
    "    # Vectorize input text\n",
    "    input_vector = vectorizer.transform([input_text]).toarray()\n",
    "\n",
    "    # Use the ensemble model for prediction\n",
    "    prediction = ensemble_model.predict(input_vector)[0]\n",
    "\n",
    "    # Convert numeric prediction to label\n",
    "    label = \"SPAM\" if prediction == 1 else \"HAM\"\n",
    "\n",
    "    # Display result\n",
    "    print('Predicted Label:', label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78324f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkSpam('Update_Now - Xmas Offer! Latest Motorola, SonyEricsson & Nokia & FREE Bluetooth! Double Mins & 1000 Txt on Orange. Call MobileUpd8 on 08000839402 or call2optout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc04319",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkSpam('hi today is my birthday, if u come to party u can won one lakhs of prize money?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1915a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkSpam('Congratulations! Youve won a $1000 Walmart gift card. Go to [link] to claim now!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeaec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkSpam('URGENT: Your account has been suspended. Verify at [phishy link] to restore access.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933b6be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
